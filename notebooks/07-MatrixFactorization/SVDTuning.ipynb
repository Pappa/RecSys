{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SVD Hyperparameter Tuning\n",
        "\n",
        "This notebook demonstrates how to tune the hyperparameters of the SVD algorithm using GridSearchCV and compares the performance of tuned vs untuned SVD against random recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup and Imports\n",
        "\n",
        "First, let's import the necessary libraries and set up our random seeds for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from recsys.MovieLens import MovieLens\n",
        "from surprise import SVD\n",
        "from surprise import NormalPredictor\n",
        "from recsys.Evaluator import Evaluator\n",
        "from surprise.model_selection import GridSearchCV\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data\n",
        "\n",
        "Load the MovieLens dataset and prepare it for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lens, ratings_data, rankings = MovieLens.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Grid Search for Best Parameters\n",
        "\n",
        "We'll use GridSearchCV to find the optimal hyperparameters for the SVD algorithm. We'll search over:\n",
        "- Number of epochs (20, 30)\n",
        "- Learning rate (0.005, 0.010)\n",
        "- Number of factors (50, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Searching for best parameters...\")\n",
        "param_grid = {\n",
        "    'n_epochs': [20, 30],\n",
        "    'lr_all': [0.005, 0.010],\n",
        "    'n_factors': [50, 100]\n",
        "}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "\n",
        "gs.fit(ratings_data)\n",
        "\n",
        "# best RMSE score\n",
        "print(\"Best RMSE score attained: \", gs.best_score['rmse'])\n",
        "\n",
        "# combination of parameters that gave the best RMSE score\n",
        "print(\"Best parameters:\", gs.best_params['rmse'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize Evaluator and Add Algorithms\n",
        "\n",
        "Now we'll create an evaluator and add three algorithms to compare:\n",
        "1. SVD with tuned parameters\n",
        "2. SVD with default parameters\n",
        "3. Random recommendations (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator = Evaluator(ratings_data, rankings)\n",
        "\n",
        "# Add tuned SVD\n",
        "params = gs.best_params['rmse']\n",
        "svd_tuned = SVD(n_epochs=params['n_epochs'], \n",
        "               lr_all=params['lr_all'], \n",
        "               n_factors=params['n_factors'],\n",
        "               verbose=False)\n",
        "evaluator.add_algorithm(svd_tuned, \"SVD - Tuned\")\n",
        "\n",
        "# Add untuned SVD\n",
        "svd_untuned = SVD(verbose=False)\n",
        "evaluator.add_algorithm(svd_untuned, \"SVD - Untuned\")\n",
        "\n",
        "# Add random recommendations as baseline\n",
        "random_rec = NormalPredictor()\n",
        "evaluator.add_algorithm(random_rec, \"Random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = evaluator.evaluate(top_n_metrics=True)\n",
        "\n",
        "results.to_df()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample Recommendations\n",
        "\n",
        "Generate and display some sample recommendations using the evaluated algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "samples = evaluator.sample_top_n_recs(uid=85)\n",
        "\n",
        "for algorithm, recs in samples.items():\n",
        "    print(f\"{algorithm}\")\n",
        "    movie_names = lens.get_movie_names(recs)\n",
        "    for movie_name in movie_names:\n",
        "        print(f\"  {movie_name}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "RecSys",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
