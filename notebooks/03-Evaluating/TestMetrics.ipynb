{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluating Recommender System Metrics\n",
        "\n",
        "This notebook demonstrates how to evaluate a recommender system using various metrics including:\n",
        "\n",
        "| Metric    |      |\n",
        "|-----------|------|\n",
        "| RMSE      | Root Mean Squared Error. Lower values mean better accuracy. |\n",
        "| MAE       |  Mean Absolute Error. Lower values mean better accuracy. |\n",
        "| HR        |   Hit Rate; how often we are able to recommend a left-out rating. Higher is better. |\n",
        "| cHR       |  Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better. |\n",
        "| ARHR      | Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better. |\n",
        "| Coverage  | Ratio of users for whom recommendations above a certain threshold exist. Higher is better. |\n",
        "| Diversity | 1-S, where S is the average similarity score between every possible pair of recommendations for a given user. Higher means more diverse. |\n",
        "| Novelty   |  Average popularity rank of recommended items. Higher means more novel. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from recsys.MovieLens import MovieLens\n",
        "from surprise import SVD\n",
        "from surprise import KNNBaseline\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut\n",
        "from recsys.RecommenderMetrics import RecommenderMetrics\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preview the ratings data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>31</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1260759144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1029</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1061</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1260759182</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating   timestamp\n",
              "0       1       31     2.5  1260759144\n",
              "1       1     1029     3.0  1260759179\n",
              "2       1     1061     3.0  1260759182"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_types = { 'userId': np.int32, 'movieId': np.int32, 'rating': np.float32, 'timestamp': np.int32 }\n",
        "ratings_df = pd.read_csv('../../src/recsys/data/ratings.csv', dtype=data_types)\n",
        "\n",
        "ratings_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBaseline at 0x77934e90bfe0>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize MovieLens data loader & load data\n",
        "lens, ratings_data, rankings  = MovieLens.load()\n",
        "\n",
        "# Generate item similarities so we can measure diversity later\n",
        "full_trainset = ratings_data.build_full_trainset()\n",
        "knn_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "similarities_model = KNNBaseline(sim_options=knn_options, verbose=False)\n",
        "similarities_model.fit(full_trainset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train-Test Split and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainset, testset = train_test_split(ratings_data, test_size=.25, random_state=1)\n",
        "\n",
        "algo = SVD(random_state=10, verbose=False)\n",
        "algo.fit(trainset)\n",
        "\n",
        "predictions = algo.test(testset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.9033701087151801\n",
            "MAE: 0.6977882196132263\n"
          ]
        }
      ],
      "source": [
        "print(f\"RMSE: {RecommenderMetrics.rmse(predictions)}\")\n",
        "print(f\"MAE: {RecommenderMetrics.mae(predictions)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Top-N Recommendations using Leave-One-Out Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit Rate: 0.02981\n",
            "rHR (Hit Rate by rating value):\n",
            "\t3.5: 0.01724\n",
            "\t4.0: 0.04255\n",
            "\t4.5: 0.02083\n",
            "\t5.0: 0.06803\n",
            "cHR (Cumulative Hit Rate, rating >= 4): 0.02832\n",
            "ARHR (Average Reciprocal Hit Rank): 0.01116\n"
          ]
        }
      ],
      "source": [
        "# Set aside one rating per user for testing\n",
        "loo_iterator = LeaveOneOut(n_splits=1, random_state=1)\n",
        "\n",
        "for trainset, testset in loo_iterator.split(ratings_data):\n",
        "    # Train model without left-out ratings\n",
        "    algo.fit(trainset)\n",
        "\n",
        "    # Predicts ratings for left-out ratings only\n",
        "    loo_predictions = algo.test(testset)\n",
        "\n",
        "    # Create predictions for all ratings not in the training set\n",
        "    anti_testset = trainset.build_anti_testset()\n",
        "    all_predictions = algo.test(anti_testset)\n",
        "\n",
        "    # Calculate top n recommendations for each user\n",
        "    n=10\n",
        "    top_n_predictions = RecommenderMetrics.get_top_n(all_predictions, n=n)\n",
        "    \n",
        "    # How often we recommended a movie the user actually rated\n",
        "    # How often we recommended a movie the user actually liked\n",
        "    # Compute ARHR\n",
        "    hit_rate, cumulative_hit_rate, average_reciprocal_hit_rank = RecommenderMetrics.hit_rate_metrics(top_n_predictions, loo_predictions, 4.0)\n",
        "    \n",
        "    # Hit Rate by rating value\n",
        "    rating_hit_rate = RecommenderMetrics.rating_hit_rate(top_n_predictions, loo_predictions)\n",
        "    \n",
        "    print(f\"Hit Rate: {hit_rate:.5f}\")\n",
        "    print(\"rHR (Hit Rate by rating value):\")\n",
        "    for rating, rate in rating_hit_rate:\n",
        "        print(f\"\\t{rating}: {rate:.5f}\")\n",
        "    print(f\"cHR (Cumulative Hit Rate, rating >= 4): {cumulative_hit_rate:.5f}\")\n",
        "    print(f\"ARHR (Average Reciprocal Hit Rank): {average_reciprocal_hit_rank:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate Complete Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "User coverage, rating >= 4.0: 0.95529\n",
            "Diversity: 0.96652\n",
            "Novelty (average popularity rank): 491.57678\n"
          ]
        }
      ],
      "source": [
        "algo.fit(full_trainset)\n",
        "anti_testset = full_trainset.build_anti_testset()\n",
        "all_predictions = algo.test(anti_testset)\n",
        "top_n_predictions = RecommenderMetrics.get_top_n(all_predictions, n=10)\n",
        "\n",
        "minimum_rating = 4.0\n",
        "\n",
        "user_coverage = RecommenderMetrics.user_coverage(\n",
        "    top_n_predictions, full_trainset.n_users, minimum_rating=minimum_rating\n",
        ")\n",
        "diversity = RecommenderMetrics.diversity(top_n_predictions, similarities_model)\n",
        "novelty = RecommenderMetrics.novelty(top_n_predictions, rankings)\n",
        "\n",
        "print(f\"User coverage, rating >= {minimum_rating}: {user_coverage:.5f}\")\n",
        "print(f\"Diversity: {diversity:.5f}\")\n",
        "print(f\"Novelty (average popularity rank): {novelty:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
